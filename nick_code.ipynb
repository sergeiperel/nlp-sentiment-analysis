{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "143045c8-59d2-46b5-b5f6-a972cac68d33",
   "metadata": {},
   "source": [
    "### wanna etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3495701-847d-4d75-a9f0-e3dc51b8f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "125b0e2c-7d12-4b7a-831b-fdbc1f40dd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\n",
    "'text': [\"I'm gon na go to the store\", \"I wan na buy something\", \"He do n't care about it\", \"They ai n't listening\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e20314a8-25ad-4915-8d43-c20730a93d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_150k.txt', sep='\\t', header = None, names = ['feeling', 'tweet'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f342ebad-3a67-4517-abb4-e0fdd98a7295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Список целевых неформальных фраз для проверки\n",
    "\n",
    "contraction_patterns = {\n",
    "\"gon na\": \"gonna\",\n",
    "\"wan na\": \"wanna\",\n",
    "\"do n't\": \"don't\",\n",
    "\"ai n't\": \"ain't\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c61f8d30-9efe-4ca5-bb93-0275cf076d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Создаем регулярное выражение на основе списка неформальных фраз\n",
    "pattern = re.compile(r'\\b(' + '|'.join(re.escape(key) for key in contraction_patterns.keys()) + r')\\b', re.IGNORECASE)\n",
    "\n",
    "# Функция для замены неформальных фраз\n",
    "def replace_contractions(text):\n",
    "    # Проверяем, содержатся ли целевые фразы в тексте\n",
    "    if any(key in text for key in contraction_patterns.keys()):\n",
    "    # Заменяем каждую найденную фразу на нужное значение\n",
    "        return pattern.sub(lambda x: contraction_patterns[x.group(0).lower()], text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78ed4487-4c06-44ab-b63f-da75fbf54648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['tweet'].apply(replace_contractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0284205-9e34-42a5-9706-47f543a361e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Starting  back at work today   Looks like it'l...\n",
       "1         Sugar levels dropping... munchies setting in. ...\n",
       "2            @karineb22 yeah!!! have a great summer break! \n",
       "3         hannah montana was very good.  now going to re...\n",
       "4         @Mayra326 aww, have fun!  I just had my 3D las...\n",
       "                                ...                        \n",
       "149980    Had a great night at Tabs but now I'm missing ...\n",
       "149981        What a night at work.. Church in the morning \n",
       "149982    this book is terrible  im used 2 reading all  ...\n",
       "149983    @backstreetboys Updates? Any?  I miss your upd...\n",
       "149984                             @lexiewohlfort I agree! \n",
       "Name: processed_text, Length: 149985, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['processed_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee0429e5-b44d-461e-8905-02a9e69850b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "276a202a-7374-4f95-9ab7-2babbd95567b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'positive_words' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Построение частотных распределений до обработки для одиночных слов\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m positive_freq \u001b[38;5;241m=\u001b[39m Counter(\u001b[43mpositive_words\u001b[49m)\n\u001b[1;32m      3\u001b[0m negative_freq \u001b[38;5;241m=\u001b[39m Counter(negative_words)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'positive_words' is not defined"
     ]
    }
   ],
   "source": [
    "# Построение частотных распределений до обработки для одиночных слов\n",
    "positive_freq = Counter(positive_words)\n",
    "negative_freq = Counter(negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b15c29-9b84-44c4-a036-f84aa8f304bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вывод топ-слов до обработки\n",
    "print(\"Top words in positive texts (before processing):\", positive_freq.most_common(10))\n",
    "print(\"Top words in negative texts (before processing):\", negative_freq.most_common(10))\n",
    "\n",
    "# Построение облаков слов до обработки\n",
    "def plot_wordcloud(freq_dist, title):\n",
    "    wordcloud = WordCloud(width=800, height=400).generate_from_frequencies(freq_dist)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "plot_wordcloud(positive_freq, \"Positive Texts - Word Cloud (Before Processing)\")\n",
    "plot_wordcloud(negative_freq, \"Negative Texts - Word Cloud (Before Processing)\")\n",
    "\n",
    "# Создание n-грамм (например, биграмм) для позитивных и негативных текстов\n",
    "positive_bigrams = list(ngrams(positive_words, 2))\n",
    "negative_bigrams = list(ngrams(negative_words, 2))\n",
    "\n",
    "positive_bigrams_freq = Counter(positive_bigrams)\n",
    "negative_bigrams_freq = Counter(negative_bigrams)\n",
    "\n",
    "# Построение облаков для n-грамм до обработки\n",
    "plot_wordcloud(positive_bigrams_freq, \"Positive Texts - Bigram Word Cloud (Before Processing)\")\n",
    "plot_wordcloud(negative_bigrams_freq, \"Negative Texts - Bigram Word Cloud (Before Processing)\")\n",
    "\n",
    "# Поиск пересечений для топ слов\n",
    "positive_top_words = set([word for word, _ in positive_freq.most_common(50)]) # Топ-50 позитивных слов\n",
    "negative_top_words = set([word for word, _ in negative_freq.most_common(50)]) # Топ-50 негативных слов\n",
    "common_words = positive_top_words.intersection(negative_top_words)\n",
    "\n",
    "# Удаление общих слов из частотных словарей\n",
    "positive_unique_freq = {word: freq for word, freq in positive_freq.items() if word not in common_words}\n",
    "negative_unique_freq = {word: freq for word, freq in negative_freq.items() if word not in common_words}\n",
    "\n",
    "# Поиск пересечений для биграмм\n",
    "positive_top_bigrams = set([bigram for bigram, _ in positive_bigrams_freq.most_common(50)])\n",
    "negative_top_bigrams = set([bigram for bigram, _ in negative_bigrams_freq.most_common(50)])\n",
    "common_bigrams = positive_top_bigrams.intersection(negative_top_bigrams)\n",
    "\n",
    "# Удаление общих биграмм из частотных словарей биграмм\n",
    "positive_unique_bigrams_freq = {bigram: freq for bigram, freq in positive_bigrams_freq.items() if bigram not in common_bigrams}\n",
    "negative_unique_bigrams_freq = {bigram: freq for bigram, freq in negative_bigrams_freq.items() if bigram not in common_bigrams}\n",
    "\n",
    "# Построение облаков слов после удаления пересечений\n",
    "plot_wordcloud(positive_unique_freq, \"Positive Texts - Word Cloud (After Processing)\")\n",
    "plot_wordcloud(negative_unique_freq, \"Negative Texts - Word Cloud (After Processing)\")\n",
    "\n",
    "# Построение облаков n-грамм после удаления пересечений\n",
    "plot_wordcloud(positive_unique_bigrams_freq, \"Positive Texts - Bigram Word Cloud (After Processing)\")\n",
    "plot_wordcloud(negative_unique_bigrams_freq, \"Negative Texts - Bigram Word Cloud (After Processing)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
