{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e271ba98-2115-485d-8055-dcad4fbc853c",
   "metadata": {},
   "source": [
    "### Data scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2d162e-2f6e-4f42-9b7b-4ae9bc7565c2",
   "metadata": {},
   "source": [
    "**Описание**\n",
    "\n",
    "Архитектура -- 3 слоя, если бы это была система баз данных. На уровне ERD. Точную дату все равно вытащить можно только по ссылке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9547d7a-afdd-4e8a-8132-f6cb3d258bd7",
   "metadata": {},
   "source": [
    "**Импорт зависимостей**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb239e64-4d21-4a65-b2df-1afe140b1b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !/usr/bin/safaridriver --enable\n",
    "\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium import webdriver\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "381ecd82-0566-452e-b7ff-d3dee4035030",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad612b1-c65c-4603-bfd5-f6644b1ce07b",
   "metadata": {},
   "source": [
    "**Сбор ссылок**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9900bdb3-f0c8-4fa6-9032-1abe5104f056",
   "metadata": {},
   "source": [
    "Открываем список твитов Илона Маска:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5887ca2a-66c9-4ee6-9d58-dd86324066fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input login:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input password:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Safari()  # Запускаем драйвер\n",
    "\n",
    "# Открываем нашу страницу:\n",
    "driver.get('https://x.com/search?q=from%3Aelonmusk&src=typed_query')  # TODO: можно добавить и date range\n",
    "time.sleep(7)  # let it load\n",
    "\n",
    "# Для начала вводим логин:\n",
    "print('input login:')\n",
    "driver.find_elements(by=By.XPATH, value='.//input[@autocomplete=\"username\"]')[0].click()\n",
    "driver.find_elements(by=By.XPATH, value='.//input[@autocomplete=\"username\"]')[0].send_keys(getpass())\n",
    "\n",
    "# Нажимаем на третью кнопку для перехода к вводу пароля:\n",
    "driver.find_elements(by=By.XPATH, value='.//button')[2].click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Вводим пароль в появившемся втором поле для этого:\n",
    "print('input password:')\n",
    "driver.find_elements(by=By.XPATH, value='.//input')[1].click()\n",
    "driver.find_elements(by=By.XPATH, value='.//input')[1].send_keys(getpass())\n",
    "\n",
    "# Нажимаем кнопку залогиниться:\n",
    "driver.find_elements(by=By.XPATH, value='.//button')[3].click()\n",
    "time.sleep(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5759b323-2417-48ec-8993-b16f712d8d78",
   "metadata": {},
   "source": [
    "Получили список твитов Илона Маска. Теперь сохраним ссылку на каждый твит. Для этого ищем ссылку + скроллим дальше. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3f7541b-198f-4171-858e-956223597065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 good links found on 1th step\n",
      "16 good links found on 2th step\n",
      "26 good links found on 3th step\n",
      "31 good links found on 4th step\n",
      "41 good links found on 5th step\n",
      "52 good links found on 6th step\n",
      "61 good links found on 7th step\n",
      "69 good links found on 8th step\n",
      "74 good links found on 9th step\n",
      "78 good links found on 10th step\n",
      "81 good links found on 11th step\n",
      "84 good links found on 12th step\n",
      "86 good links found on 13th step\n",
      "90 good links found on 14th step\n",
      "94 good links found on 15th step\n",
      "96 good links found on 16th step\n",
      "102 good links found on 17th step\n",
      "105 good links found on 18th step\n",
      "109 good links found on 19th step\n",
      "112 good links found on 20th step\n",
      "113 good links found on 21th step\n",
      "113 good links found on 22th step\n",
      "CPU times: user 1.72 s, sys: 292 ms, total: 2.01 s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tweets_links = []\n",
    "prev_len = 0\n",
    "\n",
    "for i in range(1000):\n",
    "    driver.execute_script('window.scrollBy(0, 10000)')  # скроллим вниз\n",
    "    time.sleep(7)\n",
    "\n",
    "    cur_tweets_links_elements = driver.find_elements(by=By.XPATH, value='.//div/a')\n",
    "\n",
    "    # TODO. Почему tweets_links.extend(list(map(lambda x : x.get_attribute('href'), tweets_links))) отказался работать?\n",
    "    for cur_el in cur_tweets_links_elements:\n",
    "        tweets_links.append(cur_el.get_attribute('href'))\n",
    "\n",
    "    # how many good links we found:\n",
    "    good_links = [l for l in tweets_links if 'status' in l and 'elonmusk' in l and 'photo' not in l and 'analytics' not in l]\n",
    "    cur_len = len(list(set(good_links)))\n",
    "    print(f'{cur_len} good links found on {i + 1}th step')\n",
    "\n",
    "    # do we need a new scroll?\n",
    "    if cur_len == prev_len:\n",
    "        break\n",
    "    prev_len = len(list(set(good_links)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe37741-c318-42e9-852d-33a5cb886c64",
   "metadata": {},
   "source": [
    "Сохраняем результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6607857d-afe3-49a7-b3ad-64cea42a948d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.DataFrame(list(set(good_links)), columns=['tweet_link'])\n",
    "tweets_df['time'] = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89f029f7-0f27-4bbc-84bf-d1e06751f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_tweets_df = pd.read_csv('tweet_links.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32fe09f3-7842-49db-9a5b-dc7d3734cb9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df = pd.concat([old_tweets_df, tweets_df]).reset_index(drop=True).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c2c8385-e805-44fd-986f-4828372914eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df.reset_index(drop=True).drop_duplicates().to_csv('tweet_links.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e41e885-2ef2-4792-81b2-1a4782545682",
   "metadata": {},
   "source": [
    "**Сбор информации по ссылкам**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8adf781-2a60-4c0f-bc30-8eac78955f80",
   "metadata": {},
   "source": [
    "Теперь отдельно обрабатываем каждую ссылку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "79ce4e6e-1c9b-4a82-b0d4-2956edc9da24",
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('tweet_links.csv').iloc[:,1].unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f4bba05-344d-4562-aa99-569370ee5876",
   "metadata": {},
   "source": [
    "Логинимся:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "af0d5359-a0ba-4453-beb9-7c1f80cf8e0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input login:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input password:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Safari()  # Запускаем драйвер\n",
    "\n",
    "# Открываем нашу страницу:\n",
    "driver.get('https://x.com/search?q=from%3Aelonmusk&src=typed_query')  # TODO: можно добавить и date range\n",
    "time.sleep(7)  # let it load\n",
    "\n",
    "# Для начала вводим логин:\n",
    "print('input login:')\n",
    "driver.find_elements(by=By.XPATH, value='.//input[@autocomplete=\"username\"]')[0].click()\n",
    "driver.find_elements(by=By.XPATH, value='.//input[@autocomplete=\"username\"]')[0].send_keys(getpass())  # are\n",
    "\n",
    "# Нажимаем на третью кнопку для перехода к вводу пароля:\n",
    "driver.find_elements(by=By.XPATH, value='.//button')[2].click()\n",
    "time.sleep(3)\n",
    "\n",
    "# Вводим пароль в появившемся втором поле для этого:\n",
    "print('input password:')\n",
    "driver.find_elements(by=By.XPATH, value='.//input')[1].click()\n",
    "driver.find_elements(by=By.XPATH, value='.//input')[1].send_keys(getpass())\n",
    "\n",
    "# Нажимаем кнопку залогиниться:\n",
    "driver.find_elements(by=By.XPATH, value='.//button')[3].click()\n",
    "time.sleep(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0cf38c-445e-408e-bbcf-e4a09f4271c8",
   "metadata": {},
   "source": [
    "Собираем инфу:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "d4580e3e-e5fb-4710-943c-50b117c9dbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 out of 128 done\n",
      "2 out of 128 done\n",
      "3 out of 128 done\n",
      "4 out of 128 done\n",
      "5 out of 128 done\n",
      "6 out of 128 done\n",
      "7 out of 128 done\n",
      "8 out of 128 done\n",
      "9 out of 128 done\n",
      "10 out of 128 done\n",
      "11 out of 128 done\n",
      "12 out of 128 done\n",
      "13 out of 128 done\n",
      "14 out of 128 done\n",
      "15 out of 128 done\n",
      "16 out of 128 done\n",
      "17 out of 128 done\n",
      "18 out of 128 done\n",
      "19 out of 128 done\n",
      "20 out of 128 done\n",
      "21 out of 128 done\n",
      "22 out of 128 done\n",
      "23 out of 128 done\n",
      "24 out of 128 done\n",
      "25 out of 128 done\n",
      "26 out of 128 done\n",
      "27 out of 128 done\n",
      "28 out of 128 done\n",
      "29 out of 128 done\n",
      "30 out of 128 done\n",
      "31 out of 128 done\n",
      "32 out of 128 done\n",
      "33 out of 128 done\n",
      "34 out of 128 done\n",
      "35 out of 128 done\n",
      "36 out of 128 done\n",
      "37 out of 128 done\n",
      "38 out of 128 done\n",
      "39 out of 128 done\n",
      "40 out of 128 done\n",
      "41 out of 128 done\n",
      "42 out of 128 done\n",
      "43 out of 128 done\n",
      "44 out of 128 done\n",
      "45 out of 128 done\n",
      "46 out of 128 done\n",
      "47 out of 128 done\n",
      "48 out of 128 done\n",
      "49 out of 128 done\n",
      "50 out of 128 done\n",
      "51 out of 128 done\n",
      "52 out of 128 done\n",
      "53 out of 128 done\n",
      "54 out of 128 done\n",
      "55 out of 128 done\n",
      "56 out of 128 done\n",
      "57 out of 128 done\n",
      "58 out of 128 done\n",
      "59 out of 128 done\n",
      "60 out of 128 done\n",
      "61 out of 128 done\n",
      "62 out of 128 done\n",
      "63 out of 128 done\n",
      "64 out of 128 done\n",
      "65 out of 128 done\n",
      "66 out of 128 done\n",
      "67 out of 128 done\n",
      "68 out of 128 done\n",
      "69 out of 128 done\n",
      "70 out of 128 done\n",
      "71 out of 128 done\n",
      "72 out of 128 done\n",
      "73 out of 128 done\n",
      "74 out of 128 done\n",
      "75 out of 128 done\n",
      "76 out of 128 done\n",
      "77 out of 128 done\n",
      "78 out of 128 done\n",
      "79 out of 128 done\n",
      "80 out of 128 done\n",
      "81 out of 128 done\n",
      "82 out of 128 done\n",
      "83 out of 128 done\n",
      "84 out of 128 done\n",
      "85 out of 128 done\n",
      "86 out of 128 done\n",
      "87 out of 128 done\n",
      "88 out of 128 done\n",
      "89 out of 128 done\n",
      "90 out of 128 done\n",
      "91 out of 128 done\n",
      "92 out of 128 done\n",
      "93 out of 128 done\n",
      "94 out of 128 done\n",
      "95 out of 128 done\n",
      "96 out of 128 done\n",
      "97 out of 128 done\n",
      "98 out of 128 done\n",
      "99 out of 128 done\n",
      "100 out of 128 done\n",
      "101 out of 128 done\n",
      "102 out of 128 done\n",
      "103 out of 128 done\n",
      "104 out of 128 done\n",
      "105 out of 128 done\n",
      "106 out of 128 done\n",
      "107 out of 128 done\n",
      "108 out of 128 done\n",
      "109 out of 128 done\n",
      "110 out of 128 done\n",
      "111 out of 128 done\n",
      "112 out of 128 done\n",
      "113 out of 128 done\n",
      "114 out of 128 done\n",
      "115 out of 128 done\n",
      "116 out of 128 done\n",
      "117 out of 128 done\n",
      "118 out of 128 done\n",
      "119 out of 128 done\n",
      "120 out of 128 done\n",
      "121 out of 128 done\n",
      "122 out of 128 done\n",
      "123 out of 128 done\n",
      "124 out of 128 done\n",
      "125 out of 128 done\n",
      "126 out of 128 done\n",
      "127 out of 128 done\n",
      "128 out of 128 done\n",
      "CPU times: user 2.62 s, sys: 1.05 s, total: 3.67 s\n",
      "Wall time: 16min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "scraping_res = dict()\n",
    "\n",
    "for link_num, link in enumerate(links):\n",
    "    driver.get(link)\n",
    "    time.sleep(7)\n",
    "\n",
    "    # Код ломается на твитах Маска внутри ветки, поэтому ищем индекс его твита:\n",
    "    branch_users = driver.find_elements(by=By.XPATH, value='.//div[@data-testid=\"User-Name\"]')\n",
    "    for branch_user_ind in range(len(driver.find_elements(by=By.XPATH, value='.//div[@data-testid=\"User-Name\"]'))):\n",
    "        _, user_login = driver.find_elements(\n",
    "            by=By.XPATH, value='.//div[@data-testid=\"User-Name\"]'\n",
    "        )[branch_user_ind].text.split('@')\n",
    "        if user_login == 'elonmusk':\n",
    "            break\n",
    "\n",
    "    # Все твиты в ветке имеют одну структуру, зная индекс, достаточно легко вытаскивает содержимое:\n",
    "    user_name, user_login = driver.find_elements(by=By.XPATH, value='.//div[@data-testid=\"User-Name\"]')[branch_user_ind].text.split('@')\n",
    "    tweet_text = driver.find_elements(by=By.XPATH, value='.//div[@data-testid=\"tweetText\"]')[branch_user_ind].text\n",
    "    tweet_datetime = driver.find_elements(by=By.XPATH, value='.//time')[branch_user_ind].text\n",
    "    statistics = driver.find_elements(by=By.XPATH, value='.//div[@role=\"group\"]')[branch_user_ind].get_attribute('aria-label')\n",
    "    \n",
    "    scraping_res[link] = (\n",
    "        user_name, \n",
    "        user_login, \n",
    "        tweet_text,\n",
    "        tweet_datetime,\n",
    "        statistics\n",
    "    )\n",
    "\n",
    "    print(f'{link_num + 1} out of {len(links)} done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31215d2d-6c5a-4fdb-88d1-af7dd262efe3",
   "metadata": {},
   "source": [
    "Сохраняем в формате нашего датасета. Сначала в нашем формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "4ed42c3c-8390-4c56-a581-0b53819f2d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    data=scraping_res.values(), \n",
    "    index=scraping_res.keys(),\n",
    "    columns=[\n",
    "        'user_name', \n",
    "        'user_login',\n",
    "        'tweet_text',\n",
    "        'tweet_datetime',\n",
    "        'statistics'\n",
    "    ]\n",
    ").to_csv('tweet_contents.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31cbd42-c9ef-40a9-8afe-9facc627e390",
   "metadata": {},
   "source": [
    "**Переводим в формат датасета**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987fb9cc-c20c-40aa-abb3-9fa3fcb3c0c3",
   "metadata": {},
   "source": [
    "Наконец, заключительный этап. Приводим данные к нужной нам структуре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "10d9c63e-b939-4acd-8b75-1352324fa510",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_df = pd.read_csv('tweet_contents.csv').rename(columns={'Unnamed: 0': 'link'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b070e10-b493-483a-8e83-874cac070238",
   "metadata": {},
   "source": [
    "Инициализируем колонки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "400be686-dd7b-4925-9871-8bc9850de622",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_df['user_name'] = scraped_df.user_name\n",
    "\n",
    "# Возьмем с сайта на текущий момент и введем вручсную эти значения:\n",
    "scraped_df['user_location'] = np.nan\n",
    "scraped_df['user_description'] = np.nan\n",
    "scraped_df['user_created'] = np.nan\n",
    "scraped_df['user_followers'] = np.nan\n",
    "scraped_df['user_favourites'] = np.nan\n",
    "scraped_df['user_verified'] = np.nan\n",
    "\n",
    "scraped_df['date'] = scraped_df['tweet_datetime']\n",
    "scraped_df['text'] = scraped_df.tweet_text\n",
    "\n",
    "# TODO\n",
    "scraped_df['hashtags'] = np.nan\n",
    "scraped_df['source'] = np.nan = np.nan\n",
    "\n",
    "# TODO\n",
    "scraped_df['retweets'] = scraped_df.statistics\n",
    "scraped_df['favorites'] = scraped_df.statistics\n",
    "\n",
    "# TODO\n",
    "scraped_df['is_retweet'] = np.nan\n",
    "\n",
    "needed_cols = [\n",
    "    'user_name',\n",
    "    'user_location',\n",
    "    'user_description',\n",
    "    'user_created',\n",
    "    'user_followers',\n",
    "    'user_friends',\n",
    "    'user_favourites',\n",
    "    'user_verified',\n",
    "    'date',\n",
    "    'text',\n",
    "    'hashtags',\n",
    "    'source',\n",
    "    'retweets',\n",
    "    'favorites',\n",
    "    'is_retweet'\n",
    "]\n",
    "\n",
    "res_df = scraped_df.loc[:, needed_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022066d0-0ade-4950-aa85-6d6b7f8aaf9d",
   "metadata": {},
   "source": [
    "Теперь дополнительно обрабатываем каждую, чтобы привести их к нужному формату и типу данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6ff878fd-81e5-4a9a-b9c6-60c8136b6984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_location</th>\n",
       "      <th>user_description</th>\n",
       "      <th>user_created</th>\n",
       "      <th>user_followers</th>\n",
       "      <th>user_friends</th>\n",
       "      <th>user_favourites</th>\n",
       "      <th>user_verified</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>source</th>\n",
       "      <th>retweets</th>\n",
       "      <th>favorites</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9:03 PM · Dec 25, 2024</td>\n",
       "      <td>Who let the DOGE out?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16833 replies, 37448 reposts, 479288 likes, 65...</td>\n",
       "      <td>16833 replies, 37448 reposts, 479288 likes, 65...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1:24 AM · Dec 28, 2024</td>\n",
       "      <td>Anyone – of any race, creed or nationality – w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30747 replies, 44791 reposts, 375927 likes, 96...</td>\n",
       "      <td>30747 replies, 44791 reposts, 375927 likes, 96...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4:10 AM · Dec 22, 2024</td>\n",
       "      <td>\"You catch the booster but throw away the rock...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16963 replies, 52779 reposts, 534066 likes, 20...</td>\n",
       "      <td>16963 replies, 52779 reposts, 534066 likes, 20...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec 25, 2024</td>\n",
       "      <td>How can the data systems be so bad?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8377 replies, 16963 reposts, 88812 likes, 2754...</td>\n",
       "      <td>8377 replies, 16963 reposts, 88812 likes, 2754...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1:31 AM · Jan 1, 2025</td>\n",
       "      <td>Interesting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>92 replies, 84 reposts, 1760 likes, 24 bookmar...</td>\n",
       "      <td>92 replies, 84 reposts, 1760 likes, 24 bookmar...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9:50 AM · Dec 31, 2024</td>\n",
       "      <td>Kekius Maximus will soon reach level 80 in har...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8212 replies, 10752 reposts, 121025 likes, 465...</td>\n",
       "      <td>8212 replies, 10752 reposts, 121025 likes, 465...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2:14 AM · Dec 28, 2024</td>\n",
       "      <td>Requiring a score above the 50th percentile in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>508 replies, 331 reposts, 2560 likes, 120 book...</td>\n",
       "      <td>508 replies, 331 reposts, 2560 likes, 120 book...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dec 24, 2024</td>\n",
       "      <td>A lot of compute is needed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3927 replies, 4840 reposts, 44336 likes, 1501 ...</td>\n",
       "      <td>3927 replies, 4840 reposts, 44336 likes, 1501 ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9:31 AM · Jan 1, 2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>61 replies, 52 reposts, 864 likes, 14 bookmark...</td>\n",
       "      <td>61 replies, 52 reposts, 864 likes, 14 bookmark...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11:12 PM · Dec 26, 2024</td>\n",
       "      <td>At risk of starting the obvious, there are man...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20309 replies, 24624 reposts, 215212 likes, 50...</td>\n",
       "      <td>20309 replies, 24624 reposts, 215212 likes, 50...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>128 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     user_name  user_location  user_description  user_created  user_followers  \\\n",
       "0    Elon Musk            NaN               NaN           NaN             NaN   \n",
       "1    Elon Musk            NaN               NaN           NaN             NaN   \n",
       "2    Elon Musk            NaN               NaN           NaN             NaN   \n",
       "3    Elon Musk            NaN               NaN           NaN             NaN   \n",
       "4    Elon Musk            NaN               NaN           NaN             NaN   \n",
       "..         ...            ...               ...           ...             ...   \n",
       "123  Elon Musk            NaN               NaN           NaN             NaN   \n",
       "124  Elon Musk            NaN               NaN           NaN             NaN   \n",
       "125  Elon Musk            NaN               NaN           NaN             NaN   \n",
       "126  Elon Musk            NaN               NaN           NaN             NaN   \n",
       "127  Elon Musk            NaN               NaN           NaN             NaN   \n",
       "\n",
       "     user_friends  user_favourites  user_verified                     date  \\\n",
       "0             NaN              NaN            NaN   9:03 PM · Dec 25, 2024   \n",
       "1             NaN              NaN            NaN   1:24 AM · Dec 28, 2024   \n",
       "2             NaN              NaN            NaN   4:10 AM · Dec 22, 2024   \n",
       "3             NaN              NaN            NaN             Dec 25, 2024   \n",
       "4             NaN              NaN            NaN    1:31 AM · Jan 1, 2025   \n",
       "..            ...              ...            ...                      ...   \n",
       "123           NaN              NaN            NaN   9:50 AM · Dec 31, 2024   \n",
       "124           NaN              NaN            NaN   2:14 AM · Dec 28, 2024   \n",
       "125           NaN              NaN            NaN             Dec 24, 2024   \n",
       "126           NaN              NaN            NaN    9:31 AM · Jan 1, 2025   \n",
       "127           NaN              NaN            NaN  11:12 PM · Dec 26, 2024   \n",
       "\n",
       "                                                  text  hashtags  source  \\\n",
       "0                               Who let the DOGE out?        NaN     NaN   \n",
       "1    Anyone – of any race, creed or nationality – w...       NaN     NaN   \n",
       "2    \"You catch the booster but throw away the rock...       NaN     NaN   \n",
       "3                  How can the data systems be so bad?       NaN     NaN   \n",
       "4                                          Interesting       NaN     NaN   \n",
       "..                                                 ...       ...     ...   \n",
       "123  Kekius Maximus will soon reach level 80 in har...       NaN     NaN   \n",
       "124  Requiring a score above the 50th percentile in...       NaN     NaN   \n",
       "125                         A lot of compute is needed       NaN     NaN   \n",
       "126                                                NaN       NaN     NaN   \n",
       "127  At risk of starting the obvious, there are man...       NaN     NaN   \n",
       "\n",
       "                                              retweets  \\\n",
       "0    16833 replies, 37448 reposts, 479288 likes, 65...   \n",
       "1    30747 replies, 44791 reposts, 375927 likes, 96...   \n",
       "2    16963 replies, 52779 reposts, 534066 likes, 20...   \n",
       "3    8377 replies, 16963 reposts, 88812 likes, 2754...   \n",
       "4    92 replies, 84 reposts, 1760 likes, 24 bookmar...   \n",
       "..                                                 ...   \n",
       "123  8212 replies, 10752 reposts, 121025 likes, 465...   \n",
       "124  508 replies, 331 reposts, 2560 likes, 120 book...   \n",
       "125  3927 replies, 4840 reposts, 44336 likes, 1501 ...   \n",
       "126  61 replies, 52 reposts, 864 likes, 14 bookmark...   \n",
       "127  20309 replies, 24624 reposts, 215212 likes, 50...   \n",
       "\n",
       "                                             favorites  is_retweet  \n",
       "0    16833 replies, 37448 reposts, 479288 likes, 65...         NaN  \n",
       "1    30747 replies, 44791 reposts, 375927 likes, 96...         NaN  \n",
       "2    16963 replies, 52779 reposts, 534066 likes, 20...         NaN  \n",
       "3    8377 replies, 16963 reposts, 88812 likes, 2754...         NaN  \n",
       "4    92 replies, 84 reposts, 1760 likes, 24 bookmar...         NaN  \n",
       "..                                                 ...         ...  \n",
       "123  8212 replies, 10752 reposts, 121025 likes, 465...         NaN  \n",
       "124  508 replies, 331 reposts, 2560 likes, 120 book...         NaN  \n",
       "125  3927 replies, 4840 reposts, 44336 likes, 1501 ...         NaN  \n",
       "126  61 replies, 52 reposts, 864 likes, 14 bookmark...         NaN  \n",
       "127  20309 replies, 24624 reposts, 215212 likes, 50...         NaN  \n",
       "\n",
       "[128 rows x 15 columns]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4911e19c-1656-4a33-935d-97528cb65b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df.to_csv('tweet_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d1b10f-1956-4bf1-981e-6ccf7fa441cc",
   "metadata": {},
   "source": [
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3777db-7f93-459f-b5f3-a2d8ffe1ef04",
   "metadata": {},
   "source": [
    "```\n",
    "%%time\n",
    "\n",
    "scraping_res = dict()\n",
    "\n",
    "for link_num, link in enumerate(links):\n",
    "    driver.get(link)\n",
    "    time.sleep(7)\n",
    "\n",
    "    # TODO. Прописать более сложные пути -- но так в\n",
    "    user_name = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[9].text\n",
    "    user_login = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[12].text\n",
    "    tweet_text = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[15].text\n",
    "    tweet_datetime = driver.find_elements(by=By.XPATH, value='.//time')[0].text\n",
    "    views_cnt = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[18].text\n",
    "    comments_cnt = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[21].text\n",
    "    reposts_cnt = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[23].text\n",
    "    likes_cnt = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[25].text\n",
    "    bookmarks_cnt = driver.find_elements(by=By.XPATH, value='.//span[@style=\"text-overflow: unset;\"]')[27].text\n",
    "\n",
    "    scraping_res[link] = (\n",
    "        user_name, \n",
    "        user_login, \n",
    "        tweet_text,\n",
    "        tweet_datetime,\n",
    "        views_cnt,\n",
    "        comments_cnt,\n",
    "        reposts_cnt,\n",
    "        likes_cnt,\n",
    "        bookmarks_cnt\n",
    "    )\n",
    "\n",
    "    print(f'{link_num + 1} out of {len(links)} done')\n",
    "\n",
    "# ...\n",
    "\n",
    "    comments_cnt, reposts_cnt, likes_cnt, bookmarks_cnt, views_cnt = re.sub(\n",
    "        ' +',\n",
    "        ' ',\n",
    "        re.sub(\n",
    "            '[a-zA-Z,]?', \n",
    "            '', \n",
    "            driver.find_elements(\n",
    "                by=By.XPATH, \n",
    "                value='.//div[@role=\"group\"]'\n",
    "            )[branch_user_ind].get_attribute('aria-label')\n",
    "        )\n",
    "    ).rstrip().split(' ')\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter-scraping-env",
   "language": "python",
   "name": "twitter-scraping-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
